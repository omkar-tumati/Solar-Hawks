# lightning.pytorch==2.1.1
seed_everything: 0

trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: logs
      name: fire_scars
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 5  # Increased from 1 to 5 to prevent premature stopping
        mode: min
  max_epochs: 100  # Increased from 5 to 100 for better convergence
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: true
  default_root_dir: ./

data:
  class_path: GenericNonGeoSegmentationDataModule
  init_args:
    batch_size: 16  # Increased from 4 to 16 for better training efficiency
    num_workers: 8
    dataset_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    output_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    rgb_indices:
      - 2
      - 1
      - 0
    train_transform:
      - class_path: albumentations.RandomCrop
        init_args:
          height: 256  # Increased from 224 to 256 for better feature capture
          width: 256
      - class_path: albumentations.HorizontalFlip
        init_args:
          p: 0.5  # Changed from 1 to 0.5 for more natural augmentation
      - class_path: albumentations.VerticalFlip  # Added vertical flip
        init_args:
          p: 0.5
      - class_path: albumentations.RandomRotate90  # Added rotation
        init_args:
          p: 0.5
      - class_path: albumentations.RandomBrightnessContrast  # Added brightness/contrast
        init_args:
          p: 0.5
      - class_path: ToTensorV2
    no_data_replace: 0
    no_label_replace: -1
    train_data_root: datasets/fire_scars_train_val/train
    train_label_data_root: datasets/fire_scars_train_val/train
    val_data_root: datasets/fire_scars_train_val/validation
    val_label_data_root: datasets/fire_scars_train_val/validation
    test_data_root: datasets/fire_scars_train_val/validation
    test_label_data_root: datasets/fire_scars_train_val/validation
    img_grep: "*_merged.tif"
    label_grep: "*.mask.tif"
    means:  # Updated means based on typical reflectance values
      - 0.0845  # Blue
      - 0.0929  # Green
      - 0.1095  # Red
      - 0.2005  # NIR
      - 0.1746  # SWIR1
      - 0.1175  # SWIR2
    stds:  # Updated standard deviations
      - 0.0448
      - 0.0462
      - 0.0537
      - 0.0867
      - 0.0897
      - 0.0755
    num_classes: 2

model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_args:
      decoder: FCNDecoder
      pretrained: true
      backbone: prithvi_vit_100
      decoder_channels: 16  # Increased from 8 to 16 for better feature extraction
      in_channels: 6
      bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      num_frames: 1
      num_classes: 2
      head_dropout: 0.1
      decoder_num_convs: 3  # Increased from 2 to 3 for better segmentation
      head_channel_list:
        - 16  # Increased from 8 to 16 to match decoder_channels
    loss: dice_cross_entropy  # Changed from dice to combined loss for handling class imbalance
    class_weights: [1.0, 8.0]  # Added class weights (Not Burned: 1.0, Burned: 8.0)
    plot_on_val: 10
    ignore_index: -1
    freeze_backbone: false
    freeze_decoder: false
    model_factory: PrithviModelFactory
    tiled_inference_parameters:
      h_crop: 512
      h_stride: 496
      w_crop: 512
      w_stride: 496
      average_patches: true

optimizer:
  class_path: torch.optim.AdamW  # Changed from Adam to AdamW
  init_args:
    lr: 0.001  # Reduced from 0.1 to 0.001 for more stable training
    weight_decay: 0.01  # Reduced from 0.05 to 0.01

lr_scheduler:
  class_path: torch.optim.lr_scheduler.CosineAnnealingLR  # Changed from ReduceLROnPlateau
  init_args:
    T_max: 50  # Half of max_epochs
    eta_min: 1e-6