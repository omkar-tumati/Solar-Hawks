# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: logs
      name: fire_scars
      log_graph: true
      default_hp_metric: false
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: ModelCheckpoint
      init_args:
        monitor: val/loss
        save_top_k: 1
        mode: min
        filename: best-checkpoint
  max_epochs: 150  # Increased to allow more training time
  check_val_every_n_epoch: 1
  log_every_n_steps: 20
  enable_checkpointing: true
  default_root_dir: ./

data:
  class_path: GenericNonGeoSegmentationDataModule
  init_args:
    batch_size: 8  # Increased batch size for better gradient stability
    num_workers: 4
    dataset_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    output_bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    rgb_indices:
      - 2
      - 1
      - 0
    train_transform:
      - class_path: albumentations.RandomCrop
        init_args:
          height: 224
          width: 224
      - class_path: albumentations.HorizontalFlip
        init_args:
          p: 0.5
      - class_path: albumentations.ShiftScaleRotate  # New augmentation
        init_args:
          shift_limit: 0.0625
          scale_limit: 0.2
          rotate_limit: 15
          p: 0.5
      - class_path: albumentations.RandomBrightnessContrast  # New augmentation
        init_args:
          brightness_limit: 0.2
          contrast_limit: 0.2
          p: 0.5
      - class_path: ToTensorV2
    no_data_replace: 0
    no_label_replace: -1
    train_data_root: datasets/fire_scars_train_val/train
    train_label_data_root: datasets/fire_scars_train_val/train
    val_data_root: datasets/fire_scars_train_val/validation
    val_label_data_root: datasets/fire_scars_train_val/validation
    test_data_root: datasets/fire_scars_train_val/validation
    test_label_data_root: datasets/fire_scars_train_val/validation
    img_grep: "*_merged.tif"
    label_grep: "*.mask.tif"
    means:
      - 0.033349706741586264
      - 0.05701185520536176
      - 0.05889748132001316
      - 0.2323245113436119
      - 0.1972854853760658
      - 0.11944914225186566
    stds:
      - 0.02269135568823774
      - 0.026807560223070237
      - 0.04004109844362779
      - 0.07791732423672691
      - 0.08708738838140137
      - 0.07241979477437814
    num_classes: 2

model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_args:
      decoder: DeepLabV3  # Changed to a more advanced decoder
      pretrained: true
      backbone: prithvi_vit_100
      decoder_channels: 256
      in_channels: 6
      bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      num_frames: 1
      num_classes: 2
      head_dropout: 0.2  # Increased dropout to 0.2 for regularization
      decoder_num_convs: 2
      head_channel_list:
        - 256
      patch_size: 16
      embed_dim: 768
      num_heads: 12
      tubelet_size: 1
    loss: dice_cross_entropy  # Combined Dice + CrossEntropy for better performance
    plot_on_val: 10
    ignore_index: -1
    freeze_backbone: false
    freeze_decoder: false
    model_factory: PrithviModelFactory
    tiled_inference_parameters:
      h_crop: 512
      h_stride: 480  # Reduced stride for more overlap in tiles
      w_crop: 512
      w_stride: 480
      average_patches: true

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 3e-5  # Slightly increased learning rate for better convergence
    betas: [0.9, 0.999]
    weight_decay: 1e-5  # Added weight decay for regularization

lr_scheduler:
  class_path: CosineAnnealingLR  # Changed to a cosine annealing schedule
  init_args:
    T_max: 10
    eta_min: 0.0
